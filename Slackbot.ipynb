{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Slackbot with bAbI implementation\n",
    "=================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###### In class we created a model that scored well on the single supporting fact task... But we couldn't tangibly use it\n",
    "---\n",
    "We wanted to put our model to the test with untrained data, **and see the output**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Our vision:\n",
    "+ Be able to use our model with our own human input\n",
    "+ Be able to actually see the results of the model, instead of just seeing the score\n",
    "+ To create a bot that would correctly predict the answer to our questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Challenges:\n",
    "+ Complexity in saving and loading models and their weights\n",
    "+ Understanding how the input varies when using a chatbot\n",
    "+ Successfully getting the bot to output the answer back into the chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Where is Nick](http://imgur.com/uqbn3Oy)\n",
    "\n",
    "http://imgur.com/uqbn3Oy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Robot](http://imgur.com/2YqeIwq)\n",
    "\n",
    "http://imgur.com/2YqeIwq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approach\n",
    "+ Finalize the model and successfully save it\n",
    "+ Load the model into another jupyter notebook\n",
    "+ Design an input method for the user to write stories\n",
    "+ Redesign functions to take input and parse it into stories / questions\n",
    "+ Have the model successfully calculate the answer and answer in Slack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Methods:\n",
    "+ Data: Facebook bAbI EN-10k dataset to train\n",
    "+ Model: Recurrent Neural Network\n",
    "+ End-2-End Pipeline: Train model -> Model used on Slackbot -> User input into chat -> Bot output back into chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How we measure success:\n",
    "+ Test score against testing data\n",
    "+ Successfully setting up a chatbot in Slack\n",
    "+ Successfully having the chatbot give the right answer to our stories / questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How did we do?\n",
    "+ Test score: 100%\n",
    "+ Slackbot set up: @best_friend, @hopeful_friend\n",
    "+ In the end = **@no_friends**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SlackBot](http://imgur.com/a/gXftR)\n",
    "\n",
    "http://imgur.com/a/gXftR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import os\n",
    "from slackclient import SlackClient\n",
    "import re\n",
    "import tarfile\n",
    "import functools\n",
    "import numpy as np\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Establishing bot name and API \n",
    "BOT_NAME = 'hopeful_friend'\n",
    "slack_client = SlackClient('xoxp-200374995520-201140520773-201892794883-8f7016436a178221d358c3844da225b7')\n",
    "\n",
    "#Bot's ID\n",
    "BOT_ID = 'U5WB3LDLY'\n",
    "AT_BOT = \"<@\" + BOT_ID + \">\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Connect find our bot\n",
    "api_call = slack_client.api_call(\"users.list\")\n",
    "if api_call.get('ok'):\n",
    "    users = api_call.get('members')\n",
    "    #loop through to find our bot\n",
    "    for user in users:\n",
    "        if 'name' in user and user.get('name') == BOT_NAME:\n",
    "            print(\"Bot ID for '\" + user['name']\n",
    "                  + \"' is \" + user.get('id'))\n",
    "        else: \n",
    "            print(\"could not find bot user with the name \" + BOT_NAME)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Loading our trained bAbI model\n",
    "def _load_db():\n",
    "    bAbI_model = load_model(\"TrainedModel2.h5\")\n",
    "    #create a tuple to import our variables altogether and pick save them into file\n",
    "    touple = pickle.load( open(\"vocab_save.p\", \"rb\"))\n",
    "    return bAbI_model, touple\n",
    "\n",
    "model, touple = _load_db()\n",
    "vocab = touple[0]\n",
    "story_maxlen = touple[1]\n",
    "q_maxlen = touple[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#need to read from single line of slack command not from file \n",
    "#input \n",
    "# \"Mary in kitchen.//Bob in garden.//Where Mary?\" -> [[[[\"Mary\", \"in\", \"kitchen\", \".\"], [\"Bob\", ...]], [\"Where\", \"Mary\", \"?\"]]]\n",
    "# \"Mary in kitchen.//Bob in garden.//Where Mary?\".split('//') -> [\"Mary in kitchen.\", \"Bob ...\", \"Where ...\"]\n",
    "\n",
    "def parse_stories(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true,\n",
    "    only the sentences that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    question = []\n",
    "   \n",
    "    story_lines = lines.split('//')\n",
    "    story_parse = story_lines[:2]\n",
    "    story_q = story_lines[2]\n",
    "    \n",
    "    for x in story_parse:\n",
    "        x_token = tokenize(x)\n",
    "        story.extend(x_token)\n",
    "   \n",
    "    story_q = tokenize(story_q)\n",
    "    question.extend(story_q)\n",
    "       \n",
    "    data.append((story, question))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_stories(f, only_supporting=False, max_length=None):\n",
    "    '''Given a file name, read the file, retrieve the stories,\n",
    "    and then convert the sentences into a single story.\n",
    "    If max_length is supplied,\n",
    "    any stories longer than max_length tokens will be discarded.\n",
    "    '''\n",
    "    data = parse_stories(f, only_supporting=only_supporting)\n",
    "    #flatten = lambda data: functools.reduce(lambda x, y: x + y, data)\n",
    "    data = [(story, q) for story, q in data if not max_length or len(flatten(story)) < max_length]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    xs = []\n",
    "    xqs = []\n",
    "    for story, query in data:\n",
    "        for w in story:\n",
    "            print(w)\n",
    "        x = [word_idx[w] for w in story]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        # let's not forget that index 0 is reserved\n",
    "        xs.append(x)\n",
    "        xqs.append(xq)\n",
    "    return pad_sequences(xs, maxlen=story_maxlen), pad_sequences(xqs, maxlen=query_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Reserve 0 for masking via pad_sequences\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "print(type(word_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Receives commands directed at the bot and determines if they\n",
    "    are valid commands. If so, then acts on the commands. If not,\n",
    "    returns back what it needs for clarification.\n",
    "\"\"\"\n",
    "def handle_command(x, xq):\n",
    "    response = \"Output\"\n",
    "    response = model.predict(([x, xq]))\n",
    "    response = np.argmax(response) - 1\n",
    "    response = vocab[response]\n",
    "    print(vocab)\n",
    "    return response\n",
    "    \n",
    "    \"\"\"\n",
    "    slack_client.api_call(\"chat.postMessage\", channel=channel,\n",
    "                          text=response, as_user=True)\n",
    "    \"\"\"\n",
    "def parse_slack_output(slack_rtm_output):\n",
    "    \"\"\"\n",
    "        The Slack Real Time Messaging API is an events firehose.\n",
    "        this parsing function returns None unless a message is\n",
    "        directed at the Bot, based on its ID.\n",
    "    \"\"\"\n",
    "    output_list = slack_rtm_output\n",
    "    if output_list and len(output_list) > 0:\n",
    "        for output in output_list:\n",
    "            if output and 'text' in output and AT_BOT in output['text']:\n",
    "                # return text after the @ mention, whitespace removed\n",
    "                return output['text'].split(AT_BOT)[1].strip().lower(), \\\n",
    "                       output['channel']\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed. Invalid slack token or bot ID\n"
     ]
    }
   ],
   "source": [
    "READ_WEBSOCKET_DELAY = 1\n",
    "if slack_client.rtm_connect():\n",
    "    print(\"StarterBot connected and running!\")\n",
    "    while True:\n",
    "        command, channel = parse_slack_output(slack_client.rtm_read())\n",
    "        if command and channel:\n",
    "            \n",
    "            command = get_stories(command)\n",
    "            x, xq = vectorize_stories(command, word_idx, story_maxlen, query_maxlen)\n",
    "            \n",
    "            handle_command(x, xq)\n",
    "            \n",
    "        time.sleep(READ_WEBSOCKET_DELAY)\n",
    "else:\n",
    "    print(\"Connection failed. Invalid slack token or bot ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['John', 'went', 'to', 'the', 'hallway', '.', 'Sandra', 'journeyed', 'to', 'the', 'kitchen', '.'], ['Where', 'is', 'Sandra', '?'])]\n",
      "John\n",
      "went\n",
      "to\n",
      "the\n",
      "hallway\n",
      ".\n",
      "Sandra\n",
      "journeyed\n",
      "to\n",
      "the\n",
      "kitchen\n",
      ".\n",
      "['.', '?', 'Daniel', 'John', 'Mary', 'Sandra', 'Where', 'back', 'bathroom', 'bedroom', 'garden', 'hallway', 'is', 'journeyed', 'kitchen', 'moved', 'office', 'the', 'to', 'travelled', 'went']\n",
      "-------\n",
      "kitchen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "test_str = \"John went to the hallway. // Sandra journeyed to the kitchen. // Where is Sandra?\"\n",
    "test_str = get_stories(test_str)\n",
    "print(test_str)\n",
    "\n",
    "x, xq = vectorize_stories(test_str, word_idx, story_maxlen, q_maxlen)\n",
    "ans = handle_command(x, xq)\n",
    "print(\"-------\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion:\n",
    "#### What we learned:\n",
    "+ How to train a model using labeled datasets\n",
    "+ What features of the model influence how well it does against unseen data\n",
    "+ Getting comfortable with using different APIs\n",
    "+ How to create a bot on slack using it's API\n",
    "+ How to implement a created model into a chatbot\n",
    "+ A great understanding of all the functions that are used in creating a bAbI NLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Room for improvement:\n",
    "+ **LOTS!**\n",
    "+ Successfully have the chatbot reply to the Slack user\n",
    "+ Successfully feeling comfortable using the bot and getting it active\n",
    "+ Making specialized bots that would be more useful in slack channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A big thank you to Raymond & Henry for a great class and a great 4 weeks in Cape Town! :)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
